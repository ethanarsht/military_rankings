{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling the data (Archival)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data scraped from the Wikipedia tables is not fully structured. The battle outcomes are not clearly paired with sets of belligerents, and the forces and casualties fields are not consistently formatted.\n",
    "\n",
    "To deal with this, ethanarsht hand-labeled most of the battles in Excel. (Mad props; this is a ton of data to deal with in that manner.) This notebook preserves most of that workflow, with minor edits to the `pandas` code to bring it up to speed with the 2020 library and Python 3.7. \n",
    "\n",
    "It is *not* really meant to be run from scratch - to recreate the workflow exactly, you'd need to label the data yourself in an external file editor. Instead, I'm preserving it as a record of some of the data manipulation steps that were taken intermediately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import iand, ior\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_result_column = pd.read_csv('./data/result_column.csv', names=['Battle', 'leader', 'pos', 'Result', 'VorD'])\n",
    "old_result_column['Battle'] = old_result_column.Battle.map(lambda s: s.replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_outcomes = pd.merge(results, old_result_column, how='outer', on=['Battle', 'leader', 'pos', 'Result'])\n",
    "results_with_outcomes.dropna(subset=('VorD', ), inplace=True)\n",
    "results_with_outcomes.drop_duplicates(subset=('Battle', 'Date', 'VorD'), inplace=True)\n",
    "\n",
    "results_with_outcomes.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old results merge\n",
    "df_more_results = pd.merge(df_comm, df_results, how = 'outer', on = ['Battle', 'belligerent', 'pos', 'Result'])\n",
    "df_more_results = df_more_results[df_more_results.VorD.isnull()]\n",
    "df_more_results = df_more_results.drop_duplicates(subset = ['Battle', 'Date', 'VorD'])\n",
    "df_more_results.to_csv('./data/adding_results_10.21.csv', encoding = 'utf-8')\n",
    "\n",
    "df_more_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More data inspection?\n",
    "\n",
    "df_vl = pd.merge(results, old_result_column, how='outer', on=['Battle', 'leader', 'pos', 'Result'])\n",
    "df_vl.sort_values('VorD', inplace=True)\n",
    "\n",
    "df_vl[df_vl.belligerent == 'Ambroise de Loré']\n",
    "df_vl[df_vl.belligerent == 'Saracens']\n",
    "\n",
    "df_vl.to_csv('./data/additional_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for hand-labeling strengths\n",
    "df_strength = pd.read_csv('./data/additional_results.csv', encoding='utf-8', index_col=0)\n",
    "df_strength.drop(['Location', 'Result', 'inflicted', 'taken', 'opp'], axis=1, inplace=True)\n",
    "df_strength.sort_values('Battle', inplace=True)\n",
    "df_strength.reset_index(drop=True, inplace=True)\n",
    "df_strength.drop_duplicates(['own', 'pos'], keep='first', inplace=True)\n",
    "\n",
    "df_strength['own'] = df_strength.own.str.replace('\\r',' ').str.replace('\\n', ' ').replace('\\n', ' ')\n",
    "df_strength.to_csv('strength_entry.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strength = pd.read_excel('./data/strength_entry.xlsx', encoding='utf-8')\n",
    "df_strength['Battle'] = df_strength.Battle.str.replace(u\"â€“\", u'–').replace('_', ' ')\n",
    "df_strength.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: This may be broken as is. \n",
    "#     You may need to pass ./data/scraped_battles_data.csv \n",
    "#     instead if trying to recreate this flow from scratch.\n",
    "#     (And then posssibly fiddle some more.)\n",
    "\n",
    "df_battles = pd.read_csv('./data/battles_deduped.csv', encoding='utf-8', index_col=0)\n",
    "df_battles.drop(['taken', 'inflicted'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_strengths = pd.merge(results_with_outcomes, df_strength, how='outer', on=['Battle', 'pos'])\n",
    "results_with_strengths.drop(['own_y', 'Date_y'], axis=1, inplace=True)\n",
    "results_with_strengths.rename(columns={'Date_x': 'Date','own_x': 'own', 'belligerent_x': 'belligerent'}, inplace=True)\n",
    "results_with_strengths.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are trying to recreate this workflow, get ready for fun! \n",
    "# Label it all yourself in Excel.\n",
    "# (This cell block should run anyway by using cached data; preserving to show workflow)\n",
    "\n",
    "null_idx = reduce(lambda c, s: iand(c, results_with_strengths[s].isnull()), \n",
    "                  ['Cavalry', 'Artillery', 'Ships', 'Airforce', 'Special'], \n",
    "                  results_with_strengths.Infantry.isnull())\n",
    "\n",
    "df_str_two = results_with_strengths.loc[null_idx]\n",
    "\n",
    "df_str_two.drop_duplicates(['Battle', 'Date', 'Location', 'Result', 'pos'], inplace=True)\n",
    "\n",
    "df_merger = df_strength.drop(['Date', 'belligerent', 'own'], axis=1)\n",
    "df_merger.drop_duplicates(inplace=True)\n",
    "\n",
    "df_str_two = pd.merge(df_str_two, df_merger, on=['Battle', 'pos'], how='outer')\n",
    "\n",
    "df_str_two.dropna(subset=['Date', 'Location', 'Result'], inplace=True)\n",
    "df_str_two.dropna(subset=['VorD'], inplace=True)\n",
    "\n",
    "# df_str_two.to_csv('strength_entry_two.csv')\n",
    "df_str_two.drop(['Infantry', 'Cavalry', 'Artillery', 'Ships', 'Airforce', 'Special'], axis=1, inplace=True)\n",
    "\n",
    "df_partial = pd.read_excel('PARTIAL_strength_entry_two.xlsx', encoding='utf-8')\n",
    "df_partial = df_partial.drop(['Date', 'Location', 'Result', 'belligerent','own', 'Column1'],axis = 1)\n",
    "df_finish = pd.merge(df_str_two, df_partial, on = ['Battle', 'pos', 'VorD'], how = 'outer')\n",
    "drop_list = list(df_finish[df_finish['Date'].isnull()].index)\n",
    "df_finish = df_finish.drop(drop_list)\n",
    "df_finish.to_csv('last_strength_entry.csv', encoding='utf-8')\n",
    "\n",
    "df_more_strength = pd.read_excel('last_strength_entry.xlsx')\n",
    "df_more_strength = pd.merge(df_more_strength, df_str_two, on = ['Battle', 'pos'], how = 'outer').drop(['own_y', 'Infantry_y', 'Cavalry_y', 'Artillery_y', 'Ships_y', 'Airforce_y', 'Special_y', 'Date_y', 'Location_y', 'Result_y', 'belligerent_y'], axis = 1).dropna(subset = ['Date_x'])\n",
    "df_more_strength.columns = df_more_strength.columns.str.replace('_x', '')\n",
    "\n",
    "df_fill_two = pd.merge(df_battles, df_more_strength, on = ['Battle', 'pos'], how='outer')\n",
    "df_fill_two.drop(['Date_y', 'Location_y', 'belligerent_y', 'Result_y', 'own_y', 'opp_y'], axis=1, inplace=True)\n",
    "\n",
    "df_fill_two.columns = df_fill_two.columns.str.replace('_x', '')\n",
    "df_fill_two = df_fill_two[df_fill_two['Infantry'].notnull() | df_fill_two['Cavalry'].notnull() | df_fill_two['Artillery'].notnull() | df_fill_two['Ships'].notnull() | df_fill_two['Airforce'].notnull() | df_fill_two['Special'].notnull()]\n",
    "df_some_strength = df_some_strength.loc[df_some_strength['Infantry'].notnull() | df_some_strength['Cavalry'].notnull() | df_some_strength['Artillery'].notnull() | df_some_strength['Ships'].notnull() | df_some_strength['Airforce'].notnull() | df_some_strength['Special'].notnull()]\n",
    "df_all_strength = pd.concat([df_fill_two, df_some_strength]).reset_index(drop = True)\n",
    "df_char = df_all_strength[df_all_strength.Date.isnull()]\n",
    "\n",
    "df_char.to_excel('special_character_fix.xlsx')\n",
    "df_all_strength.to_excel('all_strength_probably.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure swapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIT_TYPES = ('Infantry', 'Cavalry', 'Artillery', 'Ships', 'Airforce', 'Special')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strength_all = pd.read_excel('./data/all_strength_probably.xlsx')\n",
    "df_strength_all.loc[9988, 'Infantry'] = 2000\n",
    "df_strength_all.drop_duplicates(inplace=True)\n",
    "\n",
    "print(len(df_strength_all))\n",
    "df_strength_all.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = df_strength_all.loc[df_strength_all.pos == 'L']\n",
    "df_left.drop(['Date', 'Location', 'Result', 'belligerent', 'opp', 'own'], axis=1, inplace=True)\n",
    "df_left.drop_duplicates(subset=['Battle'], inplace=True)\n",
    "df_left.dropna(subset=['Infantry', 'Cavalry', 'Artillery', 'Ships', 'Airforce', 'Special'], how='all', inplace=True)\n",
    "\n",
    "df_right = df_strength_all.loc[df_strength_all.pos == 'R']\n",
    "df_right.drop_duplicates(subset=['Battle'], inplace=True)\n",
    "df_right.drop(['Date', 'Location', 'Result', 'belligerent', 'opp', 'own', 'VorD'], axis=1, inplace=True)\n",
    "df_right.dropna(subset=['Infantry', 'Cavalry', 'Artillery', 'Ships', 'Airforce', 'Special'], how='all', inplace=True)\n",
    "\n",
    "df_model = pd.merge(df_left, df_right, on='Battle', how='outer')\n",
    "df_model.dropna(subset=['pos_x', 'pos_y'], inplace=True)\n",
    "df_model.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(len(df_model))\n",
    "df_model.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = df_model.loc[df_model.VorD == 'V']\n",
    "df_switch = df_model.sample(n=374).copy()\n",
    "df_switch['VorD'] = 'D'\n",
    "\n",
    "def swap_cols(df, col):\n",
    "    \"\"\"Swap x and y column contents.\"\"\"\n",
    "    df[f\"{col}_x\"], df[f\"{col}_y\"] = df[f\"{col}_y\"], df[f\"{col}_x\"]\n",
    "    return df\n",
    "\n",
    "for unit_type in UNIT_TYPES:\n",
    "    _ = swap_cols(df_switch, unit_type)\n",
    "\n",
    "df_model.drop(df_switch.index, inplace=True)\n",
    "df_model = pd.concat([df_model, df_switch])\n",
    "\n",
    "# ?\n",
    "df_model.loc[2378, 'Infantry_y'] = 25000\n",
    "df_model.loc[2363, 'Infantry_x'] = 500\n",
    "\n",
    "df_model = df_model.loc[df_model.Infantry_x != 1.0]\n",
    "df_model = df_model.loc[df_model.Infantry_y != 1.0]\n",
    "\n",
    "df_model.fillna(0, inplace=True)\n",
    "\n",
    "for unit_type in UNIT_TYPES:\n",
    "    x, y = df_model[f\"{unit_type}_x\"], df_model[f\"{unit_type}_y\"]\n",
    "    df_model[f\"{unit_type}_diff\"] = (x - y) / (x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df_model[['VorD', 'Battle'] + [f\"{unit_type}_diff\" for unit_type in UNIT_TYPES]]\n",
    "\n",
    "df_diff = df_diff.loc[df_diff.VorD != 'I']\n",
    "df_diff.drop(174, inplace=True)\n",
    "df_diff.fillna(0, inplace=True)\n",
    "\n",
    "df_x = df_diff.iloc[:, 2:-1]\n",
    "df_x.drop('Artillery_diff', axis=1, inplace=True)\n",
    "\n",
    "df_y = df_diff.iloc[:, 0:1]\n",
    "df_y['VorD'] = df_y.VorD.replace('V', 1).replace('D', 0).replace('L', 0).replace('v', 1).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and save logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(df_x, df_y)\n",
    "\n",
    "with open('./data/saved_logistic_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(lr, f)\n",
    "\n",
    "lr.score(df_x, df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final changes to strengths table\n",
    "\n",
    "NB: I'm not sure why this was done after computing the logistic regression instead of before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand corrections\n",
    "# Would be nice if these were documented?\n",
    "# (They were all hand-inputted anyway, I believe...)\n",
    "df_strength_all.loc[60, 'VorD'] = 'V'\n",
    "df_strength_all.loc[61, 'VorD'] = 'V'\n",
    "df_strength_all.loc[3479:3485, 'VorD'] = 'V'\n",
    "df_strength_all.loc[3485, 'VorD'] = 'D'\n",
    "df_strength_all.loc[3802:3803, 'VorD'] = 'V'\n",
    "df_strength_all.loc[3804:3807, 'VorD'] = 'D'\n",
    "df_strength_all.loc[4142:4143, 'VorD'] = 'D'\n",
    "\n",
    "# Corrections for inconsistent notations\n",
    "df_strength_all['VorD'] = df_strength_all.VorD.str.replace('L', 'D')\n",
    "df_strength_all['VorD'] = df_strength_all.VorD.str.replace('v', 'V')\n",
    "df_strength_all['VorD'] = df_strength_all.VorD.str.replace('W', 'V')\n",
    "\n",
    "# More hand tweaks...\n",
    "null_fill = df_strength_all.loc[df_strength_all.VorD.isnull()]\n",
    "\n",
    "null_fill['VorD'] = ['V', 'D', 'D', 'V', 'V', 'D', 'V', 'V', 'V', \n",
    "                     'V', 'D', 'D', 'D', 'D', 'V', 'V', 'V', 'V', \n",
    "                     'V', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D',\n",
    "                     'D', 'D', 'D', 'D', 'V', 'V', 'V', 'V', 'V', \n",
    "                     'D', 'D', 'D', 'D', 'V', 'V', 'D', 'D', 'D', \n",
    "                     'D', np.NaN, 'D', np.NaN]\n",
    "\n",
    "df_strength_all.VorD.loc[null_fill.index] = null_fill['VorD']\n",
    "df_strength_all = df_strength_all.loc[df_strength_all.belligerent != 'Sweden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract years from dates\n",
    "def get_year(row):\n",
    "    d = row.Date\n",
    "    i = row.name\n",
    "    \n",
    "    if isinstance(d, str):\n",
    "        if re.search(r'[12]\\d{3}', d):\n",
    "            year = re.search(r'[12]\\d{3}', d).group(0)\n",
    "            year = int(year)\n",
    "            \n",
    "            if 'BC' in d:\n",
    "                year *= -1\n",
    "            \n",
    "            return year\n",
    "                            \n",
    "        elif re.search(r'[12]\\d{2}', d):\n",
    "            year = re.search(r'[12]\\d{2}', d).group(0)\n",
    "            year = int(year)\n",
    "            \n",
    "            if 'BC' in d:\n",
    "                year *= -1\n",
    "                \n",
    "            return year\n",
    "    \n",
    "    return None\n",
    "\n",
    "df_strength_all['year'] = df_strength_all.apply(get_year, axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only save if you are OK overwriting the original archived data\n",
    "# df_strength_all.to_csv('./data/current_run.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
